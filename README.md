# TPI TeorÃ­a de Control: SimulaciÃ³n de Controlador PD para Rate Limiter

**Alumno:** MatÃ­as Ezequiel NuÃ±ez  
**Materia:** TeorÃ­a de Control (K4572) - UTN FRBA

Este repositorio contiene la simulaciÃ³n y el anÃ¡lisis del Trabajo PrÃ¡ctico Integrador que modela un sistema de **Rate Limiting** como un lazo de control cerrado con **Controlador PD** (Proporcional-Derivativo).

## ðŸš€ Acceso RÃ¡pido - Google Colab

**Para ejecutar la simulaciÃ³n sin instalar nada, haga clic aquÃ­:**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matiasnu/tpi-teoria-de-control/blob/master/notebooks/simulacion_controlador.ipynb)

La simulaciÃ³n interactiva incluye controles deslizantes (sliders) para ajustar las ganancias Kp y Kd en tiempo real, y permite cambiar entre diferentes escenarios de carga (RÃ¡fagas vs. Ataque DoS).

## ðŸ“‹ DescripciÃ³n del Sistema

A diferencia del enfoque clÃ¡sico de Token Bucket (que funciona como un controlador PI), este proyecto implementa:

1. **Controlador PD:** $G_c(s) = K_p + K_d \cdot s$
2. **Actuador con Memoria:** El mecanismo de asignaciÃ³n de recursos (Bucket/Autoscaler) actÃºa como un integrador puro en el lazo directo
3. **RealimentaciÃ³n Unitaria:** $H(s) = 1$

### Objetivo del TPI

Validar que el sistema es estable y presenta **error estacionario nulo** ($e_{ss}=0$) gracias a la naturaleza "Tipo 1" del lazo completo, a pesar de que el controlador es PD (sin acciÃ³n integral explÃ­cita).

La clave es que el **actuador tiene memoria** (acumula recursos/tokens), lo que aÃ±ade un polo en el origen al lazo abierto, convirtiendo al sistema en Tipo 1.

## ðŸ§ª Escenarios de SimulaciÃ³n

La simulaciÃ³n analiza el comportamiento del sistema bajo dos escenarios:

1. **RÃ¡fagas de TrÃ¡fico:** EvalÃºa la respuesta transitoria ante picos cortos de trÃ¡fico (t=5s y t=15s)
2. **Ataque DoS Sostenido:** Comprueba la estabilidad y el error en estado estacionario ante una perturbaciÃ³n constante desde t=5s

## ðŸ’» InstalaciÃ³n Local (Opcional)

Si prefiere ejecutar la simulaciÃ³n localmente en lugar de usar Google Colab:

### OpciÃ³n 1: Ejecutar el Notebook Interactivo

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/matiasnu/tpi-teoria-de-control.git
   cd tpi-teoria-de-control
   ```

2. (Recomendado) Crear y activar un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Instalar las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Iniciar Jupyter Notebook:
   ```bash
   jupyter notebook
   ```

5. Abrir el archivo `notebooks/simulacion_controlador.ipynb` desde la interfaz de Jupyter

**Nota:** Para usar widgets interactivos en VSCode o Jupyter Lab, necesitarÃ¡ instalar:
```bash
pip install ipympl
```
Y usar `%matplotlib widget` en lugar de `%matplotlib inline`.

### OpciÃ³n 2: Ejecutar el Simulador Standalone

Para ejecutar el simulador grÃ¡fico sin Jupyter:

```bash
python sim/controlador_pd.py
```

Esto abrirÃ¡ una ventana interactiva con matplotlib donde podrÃ¡ ajustar los parÃ¡metros Kp y Kd mediante sliders.

## ðŸ“‚ Estructura del Proyecto

```
tpi-teoria-de-control/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ simulacion_controlador.ipynb    # Notebook interactivo (compatible con Colab)
â”‚
â”œâ”€â”€ sim/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ controlador_pd.py               # Simulador standalone con matplotlib
â”‚
â”œâ”€â”€ requirements.txt                     # Dependencias del proyecto
â””â”€â”€ README.md                            # Este archivo
```

## ðŸŽ® Uso de la SimulaciÃ³n Interactiva

### Controles Disponibles

- **Slider Kp (Ganancia Proporcional):** Rango 0.0 - 5.0
  - â†‘ Kp: Respuesta mÃ¡s rÃ¡pida, pero puede causar sobrepicos (overshoot)
  - â†“ Kp: Respuesta mÃ¡s lenta y suave

- **Slider Kd (Ganancia Derivativa):** Rango 0.0 - 5.0
  - â†‘ Kd: Mayor amortiguamiento, reduce oscilaciones
  - â†“ Kd: Menor amortiguamiento

- **Selector de Escenario:**
  - **RÃ¡fagas:** Picos de trÃ¡fico cortos en t=5s (150 req/s) y t=15s (80 req/s)
  - **DoS:** Ataque sostenido de 400 req/s desde t=5s hasta el final

### GrÃ¡ficos Generados

1. **Respuesta del Sistema:** Muestra el Setpoint (Î¸áµ¢), la salida del sistema (Y) y la perturbaciÃ³n (D)
2. **Error:** Muestra e(t) = R(t) - Y(t)
3. **SeÃ±al de Control:** Muestra u(t), la salida del controlador PD

## ðŸ”¬ Resultados Esperados

### Escenario RÃ¡fagas
- El sistema debe responder rÃ¡pidamente a los picos
- Mayor Kd reduce las oscilaciones
- La salida debe volver al setpoint despuÃ©s de cada rÃ¡faga

### Escenario DoS
- **Resultado clave:** El error debe converger a cero en estado estacionario (e_ss = 0)
- Esto valida que el sistema es Tipo 1 gracias a la memoria del actuador
- El sistema debe mantener estabilidad incluso bajo carga sostenida